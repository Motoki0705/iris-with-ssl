# M-05 — Auto MPG 回帰ワークフロー検証テスト（Level 3）

## 1. 背景と狙い
- Level 3 の実装（M-01〜M-04）で構築した KNN・線形・多項式モデルと可視化機能が統合的に機能するか確認する必要がある。
- No4 演習課題の提出要件を満たすため、少なくとも 3 モデル以上を対象に学習→評価→比較→可視化の流れを再現できることをテストする。
- テスト結果・ログを記録し、judge が参照できるよう `docs/results` / `docs/trace` に整備する。

## 2. スコープ
- `tests/auto_mpg/test_workflow.py`（または既存テストを拡張）
  - `auto_mpg/knn_regressor`, `auto_mpg/linear_models`, `auto_mpg/comparison`, `auto_mpg/visualization` の API を組み合わせた統合スモークテストを実装。
  - データサンプルを縮小し、実行時間を抑えつつ主要指標と生成物の存在を確認。
- テスト実行ログと結果を `docs/trace/M-05.md` と `docs/results/M-05.md` にまとめる。

## 3. 完了条件（チェックリスト）
- [ ] 統合テストが KNN + 線形 + 多項式の少なくとも 3 モデルを評価し、`rank_models` 出力の整合性を確認。
- [ ] 可視化関数の呼び出しで `docs/results/figures/` に少なくとも 1 枚の図が生成されることを検証（生成ファイルはテスト終了後クリーンアップ可）。
- [ ] `.venv-wsl` をアクティベートし、`uv run --active pytest tests/auto_mpg/test_workflow.py` を実行。結果とコマンドを `docs/trace/M-05.md` に、サマリを `docs/results/M-05.md` に記録。
- [ ] チケットと `docs/tickets/overview.md` に成果物パス・テスト結果・レビュー待ち状態を反映。

## 4. 作業ガイド
- テストでは乱数シード固定、データ前処理の一貫性確認、生成物の一時ディレクトリ利用など再現性を重視する。
- 実行時間が長い場合は `pytest.mark.slow` を付与し、README/overview に実行目安を記載することを検討。
- 生成図のパスは `docs/results/figures/M-05_smoke.png` といったテスト専用命名を採用し、後続レビューで確認しやすくする。
- コマンドは `source .venv-wsl/bin/activate && uv run --active pytest ...` 形式で統一し、ログに環境情報（Python/uv バージョン）も記録。

## 5. 依存関係と参照資料
- 依存: M-01, M-02, M-03, M-04
- 参照: `docs/spec/requrements.md`（No4 提出要件）, `docs/spec/architecture.md`, `docs/spec/implementation-tasks.md`, `docs/spec/agents.md`

## 6. 想定担当とハンドオフ
- 担当: tester
- `docs/results/M-05.md`, `docs/trace/M-05.md` にスモークテスト結果とログをまとめ、judge が追跡できるようテストケース名・生成物パスを記載。
- judge へ引き継ぐ際は、失敗時の再現手順とクリーニング手順もあわせてチケットに記入。

## 7. 期待成果物
- テスト: `tests/auto_mpg/test_workflow.py`
- ドキュメント: `docs/results/M-05.md`
- トレース: `docs/trace/M-05.md`
- 補助生成物: `docs/results/figures/M-05_*.png`（必要に応じて）
